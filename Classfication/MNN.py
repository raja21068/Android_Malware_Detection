################################################################################################################################################################
#Dnet1 Dnet2 Dnet3 Dnet4 Dnet5 Cnet6
##### ##### ##### ##### ##### ##### --> input
##### ##### ##### ##### ##### #####
# |     |     |     |     |     |
  ###   ###   ### ###   ###   ###  --> Merge
    ###########################
       ####################
                ###  --> output
#                |
#                |
#                ^
#               M B
################################################################################################################################################################
import os
import datetime, time
import json
import numpy as np
from keras.models import model_from_json
from keras.models import Sequential
from keras.layers import Dense, Merge, Dropout
from keras.callbacks import ModelCheckpoint
import keras.optimizers
import sample_datasets
from keras.regularizers import l1, l2
#from keras.utils import plot_model
#import matplotlib.pyplot as plt
import tensorflow as tf
#tf.python.control_flow_ops = tf

################################################################################################################################################################

def dataloading(filename, AllTorOneF, NoValids):
  malwareset, benignset, malwarenames, benignnames, featNos = sample_datasets.load(filename, AllTorOneF)
  #malwareset, benignset = sample_datasets.normTwoSets(malwareset, benignset)
  if NoValids ==False:
    mXYtrain, mXYtest, mYtrain, mYtest, bXYtrain, bXYtest, bYtrain, bYtest= sample_datasets.divideTwoSets(malwareset, benignset, 0.16)
  else:
    mXYtrain, mXYtest, mYtrain, mYtest, bXYtrain, bXYtest, bYtrain, bYtest= sample_datasets.divideTwoSets(malwareset, benignset, 0.0)#2)
  #concatenate malwareSet/benignSet
  #shuffle instances in the concatenated data set
  #final training/test set seperation
  numColumn = np.shape(mXYtrain)[1]
  mbXY_train = np.concatenate((mXYtrain[:,:],bXYtrain[:,:]))
  mbXY_test = np.concatenate((mXYtest[:,:],bXYtest[:,:]))
  np.random.shuffle(mbXY_train)
  np.random.shuffle(mbXY_test)


  X_train = mbXY_train[:,0:numColumn-1]
  X_test = mbXY_test[:,0:numColumn-1]
  Y_train = mbXY_train[:,numColumn-1]
  Y_test = mbXY_test[:,numColumn-1]

  
  return X_train, X_test, Y_train, Y_test, featNos

################################################################################################################################################################

def modelgenFreeze(jsonfilename, h5filename, h5filenames, featNos, L1, L2, dropRate, reinit=False):
  if reinit == True:
    initmodel = list()
    j=0
    for i in range(6):
      if not featNos[i] == 0:
          initmodel.append(Sequential())

          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=False))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=False))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu', trainable=False))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))
          
          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=False))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=False))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu', trainable=False))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))
          
          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=False))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=False))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu', trainable=False))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))

          #for l in initmodel[j]:
          #  l.trainable = False
          
          tmpmergemodel = Sequential()
          tmpmergemodel.add(Sequential([initmodel[j]]))

          popcount = 6

          if L1 > 0.0 and L2 == 0.0:
            tmpmergemodel.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
          elif L2 > 0.0 and L1 == 0.0:
            tmpmergemodel.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
          elif L1 == 0.0 and L2 == 0.0:
            tmpmergemodel.add(Dense(500, init='glorot_normal', activation='relu'))
          else:
            popcount-=1
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            tmpmergemodel.add(Dropout(dropRate))
          else:
            popcount-=1

          if L1 > 0.0 and L2 == 0.0:
            tmpmergemodel.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
          elif L2 > 0.0 and L1 == 0.0:
            tmpmergemodel.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
          elif L1 == 0.0 and L2 == 0.0:
            tmpmergemodel.add(Dense(100, init='glorot_normal', activation='relu'))
          else:
            popcount-=1
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            tmpmergemodel.add(Dropout(dropRate))
          else:
            popcount-=1

          tmpmergemodel.add(Dense(10, init='glorot_normal', activation='relu'))
          tmpmergemodel.add(Dense(1, init='glorot_normal', activation='sigmoid'))

          tmpmergemodel.load_weights(h5filenames[i])

          tmpmergemodel.summary()
          for p in range(popcount):
            tmpmergemodel.pop()
          tmpmergemodel.summary()

          j+=1


    print('adding init nets: done')
    if len(initmodel) == 1:
      merged = initmodel[0]
    else:
      merged = Merge(initmodel, mode='concat')
    final_model = Sequential()
    final_model.add(merged)

    if L1 > 0.0 and L2 == 0.0:
        final_model.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(500, init='glorot_normal', activation='relu'))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    if L1 > 0.0 and L2 == 0.0:
        final_model.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(100, init='glorot_normal', activation='relu'))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    final_model.add(Dense(10, init='glorot_normal', activation='relu'))
    final_model.add(Dense(1, init='glorot_normal', activation='sigmoid'))

  else:
    # load json and create model
    json_file = open(jsonfilename, 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    final_model = model_from_json(loaded_model_json)
    # load weights into new model
    final_model.load_weights(h5filename)



  print('mering nets: done')
  return final_model

################################################################################################################################################################

def modelgen(jsonfilename, h5filename, featNos, L1, L2, dropRate, reinit=False):
  if reinit == True:
    initmodel = list()
    j=0
    for i in range(6):
      if not featNos[i] == 0:
          initmodel.append(Sequential())

          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu', W_regularizer=l1(L1)))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu', W_regularizer=l2(L2)))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(5000, input_dim=featNos[i], init='glorot_normal', activation='relu'))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))
          
          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu', W_regularizer=l2(L2)))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(2500, init='glorot_normal', activation='relu'))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))
          
          if L1 > 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))  
          elif L2 > 0.0 and L1 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu', W_regularizer=l2(L2)))  
          elif L1 == 0.0 and L2 == 0.0:
            initmodel[j].add(Dense(1000, init='glorot_normal', activation='relu'))
          else:
            print('L1 L2 check plz')
            exit()

          if not dropRate == 0.0:
            initmodel[j].add(Dropout(dropRate))
          j+=1

    print('adding init nets: done')
    if len(initmodel) == 1:
      merged = initmodel[0]
    else:
      merged = Merge(initmodel, mode='concat')
    final_model = Sequential()
    final_model.add(merged)

    if L1 > 0.0 and L2 == 0.0:
        final_model.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(500, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(500, init='glorot_normal', activation='relu'))
    else:
      print('L1 L2 check plz')
      exit()
  
    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    if L1 > 0.0 and L2 == 0.0:
        final_model.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l1(L1)))
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(100, init='glorot_normal', activation='relu', W_regularizer=l2(L2))) 
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(100, init='glorot_normal', activation='relu'))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    final_model.add(Dense(10, init='glorot_normal', activation='relu'))
    final_model.add(Dense(1, init='glorot_normal', activation='sigmoid'))
    print('mering nets: done')

  else:
    # load json and create model
    json_file = open(jsonfilename, 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    final_model = model_from_json(loaded_model_json)
    # load weights into new model
    final_model.load_weights(h5filename)
  
  return final_model

################################################################################################################################################################

def logResult(filename, final_model, score, preds, y_test, notrains, novalids, notests, learningRate, dropRate, L1, L2, AllTorOneF, hist):
  date = datetime.date.fromtimestamp(time.time())
  strdate = str(date)
  basename = os.path.basename(filename)
  logPath = "./static/"
  logPath += "/log/"
  logPath += basename[:-5]
  print(logPath)

  flog = open(logPath+'model_info_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.txt','w')
  flog.write('@@!\n') #delim
  flog.write(str(notrains)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(novalids)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(notests)+'\n')
  flog.write('@@!\n') #delim
  flog.write('evaluation: test socre:'+str(score[0])+'\n')
  flog.write('evaluation: test accuracy:'+str(score[1])+'\n')
  flog.write('@@!\n') #delim
  for p in preds:
    flog.write(str(p)+ ' ')
  flog.write('\n')
  flog.write('@@!\n') #delim
  for yt in y_test:
    flog.write(str(yt)+' ')
  flog.write('\n')
  flog.write(str(hist.history)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(final_model.get_config())+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(final_model.get_weights())+'\n')
  flog.close()
  json_string = final_model.to_json()
  with open(logPath+'model_json_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.js','w') as dumpfile:
      #json.dump(json_string,dumpfile)
      dumpfile.write(json_string)
  #final_model.save_weights(logPath+'model_Ws_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'.h5')

################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
#########################################################################              #########################################################################
#########################################################################  Main Start  #########################################################################
#########################################################################              #########################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################


def main(arffindex, datestr_p, learningRate_p, dropRate_p, AllTorOneF_p, L1_p, L2_p, datestr, learningRate, dropRate, AllTorOneF, L1, L2, initflag, LoadnEval, NoValids, NoCallBack, NoFreeze, noEpoch):
###############################################################################################################################################################
  seed = 7
  np.random.seed(seed)
################################################################################################################################################################
  #data loading

  farffs = open("./arffFileList.txt",'r')
  arfflist = farffs.readlines()
  farffs.close()
  if not arfflist[arffindex][:-1].find('functionSYS') == -1:
    return
  filename = "/media/ktg/New Volume/AndroidMalPaper/Arff/"
  filename += arfflist[arffindex][:-1]

  filename_p = "./static/log/"
  filename_p += arfflist[arffindex][:-1]



  if NoFreeze == False:
    h5filename = filename_p[:-5]+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+"_Freeze"+".h5"
    jsonfilename = filename_p[:-5]+"model_json_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+"_Freeze"+".js"
  else:
    h5filename = filename_p[:-5]+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5"
    jsonfilename = filename_p[:-5]+"model_json_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".js"


  X_train, X_test, Y_train, Y_test, featNos = dataloading(filename, AllTorOneF, NoValids)
  print('data loading: done')

################################################################################################################################################################
  #model generation

  if NoFreeze == False:
    h5filenames = list()
    h5filenames.append("./static/log/manifest_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    h5filenames.append("./static/log/string_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    h5filenames.append("./static/log/methodOP_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    h5filenames.append("./static/log/methodAPI_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    h5filenames.append("./static/log/functionOP_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    h5filenames.append("./static/log/functionSYS_"+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5")
    final_model = modelgenFreeze(jsonfilename, h5filename, h5filenames, featNos, L1, L2, dropRate, initflag)
  else:
      final_model = modelgen(jsonfilename, h5filename, featNos, L1, L2, dropRate, initflag)
  
################################################################################################################################################################
  #compile model

  SGD = keras.optimizers.SGD(lr=learningRate, momentum=0.5)
  #Adam = keras.optimizers.Adam(lr=learningRate)
  final_model.compile(loss='binary_crossentropy',
                optimizer= SGD,
                metrics=['accuracy'])
  print('compiling model: done')

################################################################################################################################################################
  # if only evaluation

  if LoadnEval == True:
    test_list = list()
    prevIndex = 0
    for i in range(6):
      if not featNos[i] == 0:
        test_list.append(X_test[:,prevIndex:prevIndex+featNos[i]])
        prevIndex = prevIndex+featNos[i]
    score = final_model.evaluate(test_list, Y_test, verbose=0)
    preds = final_model.predict(test_list, verbose=0)

    print(score)
    return score

################################################################################################################################################################
  #callback 

  date = datetime.date.fromtimestamp(time.time())
  strdate = str(date)
  basename = os.path.basename(filename)
  #logPath = os.path.dirname(filename)
  logPath = "./static/log/"
  logPath += basename[:-5]
  filepath=logPath+'model_Ws_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.h5'
  if NoValids == False:
    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
  else:
    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
  callbacks_list = [checkpoint]

################################################################################################################################################################
  #Fit the model

  print('start model fitting')
  startfit = time.time()
  train_list = list()
  prevIndex = 0
  for i in range(6):
  	if not featNos[i] == 0:
  		train_list.append(X_train[:,prevIndex:prevIndex+featNos[i]])
  		prevIndex = prevIndex+featNos[i]
  if NoCallBack == False:
    if NoValids == False:
      hist = final_model.fit(train_list, Y_train, validation_split=0.2, nb_epoch=noEpoch, callbacks=callbacks_list, verbose=2)
    else:
      hist = final_model.fit(train_list, Y_train, nb_epoch=noEpoch, callbacks=callbacks_list, verbose=2)
  else:
    if NoValids == False:
      hist = final_model.fit(train_list, Y_train, validation_split=0.2, nb_epoch=noEpoch, verbose=2)
    else:
      hist = final_model.fit(train_list, Y_train, nb_epoch=noEpoch, verbose=2)
  fittime = time.time()-startfit
  print('model fitted')

################################################################################################################################################################
  #evalaution

  test_list = list()
  prevIndex = 0
  for i in range(6):
  	if not featNos[i] == 0:
  		test_list.append(X_test[:,prevIndex:prevIndex+featNos[i]])
  		prevIndex = prevIndex+featNos[i]
  score = final_model.evaluate(test_list, Y_test, verbose=0)
  preds = final_model.predict(test_list, verbose=0)

  print(score)
  print("fit time: "+str(fittime))

################################################################################################################################################################
  #log result

  logResult(filename, final_model, score, preds, Y_test, int(len(Y_train)*0.8), int(len(Y_train)*0.2), int(len(Y_test)*0.8), learningRate, dropRate, L1, L2, AllTorOneF, hist)

  return score

################################################################################################################################################################


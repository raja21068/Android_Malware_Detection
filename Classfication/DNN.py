################################################################################################################################################################
#Dnet1 Dnet2 Dnet3 Dnet4 Dnet5 Cnet6
##### ##### ##### ##### ##### ##### --> input
##### ##### ##### ##### ##### #####
# |     |     |     |     |     |
  ###   ###   ### ###   ###   ###  --> Merge
    ###########################
       ####################
                ###  --> output
#                |
#                |
#                ^
#               M B
################################################################################################################################################################
import os
import datetime, time
import json
import numpy as np
from keras.models import model_from_json
from keras.models import Sequential
from keras.layers import Dense, Merge, Dropout
from keras.callbacks import ModelCheckpoint
import keras.optimizers
import sample_datasets
from keras.regularizers import l1, l2
#from keras.utils import plot_model

import tensorflow as tf


################################################################################################################################################################

def dataloading(filename, AllTorOneF, NoValids):
  malwareset, benignset, malwarenames, benignnames, featNos = sample_datasets.load(filename, AllTorOneF)
  #malwareset, benignset = sample_datasets.normTwoSets(malwareset, benignset)
  if NoValids ==False:
    mXYtrain, mXYtest, mYtrain, mYtest, bXYtrain, bXYtest, bYtrain, bYtest= sample_datasets.divideTwoSets(malwareset, benignset, 0.16)
  else:
    mXYtrain, mXYtest, mYtrain, mYtest, bXYtrain, bXYtest, bYtrain, bYtest= sample_datasets.divideTwoSets(malwareset, benignset, 0.2)
  #concatenate malwareSet/benignSet
  #shuffle instances in the concatenated data set
  #final training/test set seperation
  numColumn = np.shape(mXYtrain)[1]
  mbXY_train = np.concatenate((mXYtrain[:,:],bXYtrain[:,:]))
  mbXY_test = np.concatenate((mXYtest[:,:],bXYtest[:,:]))
  np.random.shuffle(mbXY_train)
  np.random.shuffle(mbXY_test)


  X_train = mbXY_train[:,0:numColumn-1]
  X_test = mbXY_test[:,0:numColumn-1]
  Y_train = mbXY_train[:,numColumn-1]
  Y_test = mbXY_test[:,numColumn-1]

  
  return X_train, X_test, Y_train, Y_test, featNos

################################################################################################################################################################

def modelgen(jsonfilename, h5filename, featNos, L1, L2, dropRate, reinit=False):
  if reinit == True:
    j=0
    featcount = 0
    for i in range(6):
      if not featNos[i] == 0:
        featcount+=1
    #featcount -= 4
    final_model = Sequential()

    if L1 > 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, input_dim=(featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]), init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=True))  
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(1000*featcount, input_dim=(featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]), init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=True))  
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, input_dim=(featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]), init='glorot_normal', activation='relu', trainable=True))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))
    if L1 > 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=True))  
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=True))  
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', trainable=True))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    if L1 > 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=True))  
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=True))  
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(1000*featcount, init='glorot_normal', activation='relu', trainable=True))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))
    if L1 > 0.0 and L2 == 0.0:
      final_model.add(Dense(500*featcount, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=True))  
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(500*featcount, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=True))  
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(500*featcount, init='glorot_normal', activation='relu', trainable=True))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    if L1 > 0.0 and L2 == 0.0:
      final_model.add(Dense(100*featcount, init='glorot_normal', activation='relu', W_regularizer=l1(L1), trainable=True))  
    elif L2 > 0.0 and L1 == 0.0:
      final_model.add(Dense(100*featcount, init='glorot_normal', activation='relu', W_regularizer=l2(L2), trainable=True))  
    elif L1 == 0.0 and L2 == 0.0:
      final_model.add(Dense(100*featcount, init='glorot_normal', activation='relu', trainable=True))
    else:
      print('L1 L2 check plz')
      exit()

    if not dropRate == 0.0:
      final_model.add(Dropout(dropRate))

    final_model.add(Dense(10*featcount, init='glorot_normal', activation='relu'))
    final_model.add(Dense(10, init='glorot_normal', activation='relu'))
    final_model.add(Dense(1, init='glorot_normal', activation='sigmoid'))


          
  else:
    # load json and create model
    json_file = open(jsonfilename, 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    final_model = model_from_json(loaded_model_json)
    # load weights into new model
    final_model.load_weights(h5filename)
  return final_model


################################################################################################################################################################

def logResult(filename, final_model, score, preds, y_test, notrains, novalids, notests, learningRate, dropRate, L1, L2, AllTorOneF, hist):
  date = datetime.date.fromtimestamp(time.time())
  strdate = str(date)
  basename = os.path.basename(filename)
  logPath = "./static/"
  logPath += "/log/"
  logPath += basename[:-5]
  print(logPath)

  flog = open(logPath+'model_info_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.txt','w')
  flog.write('@@!\n') #delim
  flog.write(str(notrains)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(novalids)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(notests)+'\n')
  flog.write('@@!\n') #delim
  flog.write('evaluation: test socre:'+str(score[0])+'\n')
  flog.write('evaluation: test accuracy:'+str(score[1])+'\n')
  flog.write('@@!\n') #delim
  for p in preds:
    flog.write(str(p)+ ' ')
  flog.write('\n')
  flog.write('@@!\n') #delim
  for yt in y_test:
    flog.write(str(yt)+' ')
  flog.write('\n')
  flog.write(str(hist.history)+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(final_model.get_config())+'\n')
  flog.write('@@!\n') #delim
  flog.write(str(final_model.get_weights())+'\n')
  flog.close()
  json_string = final_model.to_json()
  with open(logPath+'model_json_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.js','w') as dumpfile:
      #json.dump(json_string,dumpfile)
      dumpfile.write(json_string)
  #final_model.save_weights(logPath+'model_Ws_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'.h5')

################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
#########################################################################              #########################################################################
#########################################################################  Main Start  #########################################################################
#########################################################################              #########################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################
################################################################################################################################################################


def main(arffindex, datestr_p, learningRate_p, dropRate_p, AllTorOneF_p, L1_p, L2_p, datestr, learningRate, dropRate, AllTorOneF, L1, L2, initflag, LoadnEval, NoValids, NoCallBack, NoFreeze, noEpoch):
###############################################################################################################################################################
  seed = 7
  np.random.seed(seed)
################################################################################################################################################################
  #data loading

  farffs = open("./arffFileList.txt",'r')
  arfflist = farffs.readlines()
  farffs.close()
  if not arfflist[arffindex][:-1].find('functionSYS') == -1:
    return
  filename = "/media/ktg/New Volume/AndroidMalPaper/Arff/"
  filename += arfflist[arffindex][:-1]
  print(filename)
  filename_p = "./static/log/"
  filename_p += arfflist[arffindex][:-1]

  h5filename = filename_p[:-5]+"model_Ws_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".h5"
  jsonfilename = filename_p[:-5]+"model_json_"+datestr_p+'_'+str(learningRate_p)+'_Dr'+str(dropRate_p)+'_L1-'+str(L1_p)+'_L2-'+str(L2_p)+'_AllT|OneF-'+str(AllTorOneF_p)+".js"

  X_train, X_test, Y_train, Y_test, featNos = dataloading(filename, AllTorOneF, NoValids)
  print('data loading: done')

################################################################################################################################################################
  #model generation

  final_model = modelgen(jsonfilename, h5filename, featNos, L1, L2, dropRate, initflag)
  
################################################################################################################################################################
  #compile model

  SGD = keras.optimizers.SGD(lr=learningRate, momentum=0.5)
  #Adam = keras.optimizers.Adam(lr=learningRate)
  final_model.compile(loss='binary_crossentropy',
                optimizer= SGD,
                metrics=['accuracy'])
  print('compiling model: done')

################################################################################################################################################################
  # if only evaluation

  if LoadnEval == True:
    TotalfeatNos = featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]
    TotalInstance = np.shape(X_test)[0]
    test_list = np.empty(TotalfeatNos*TotalInstance)

    t=0
    for k in range(TotalInstance):
      prevIndex = 0
      for j in range(6):
        for i in range(featNos[j]):
          test_list[t] = X_test[k][prevIndex+i]
          t+=1
        prevIndex = prevIndex+featNos[j]

    test_list = np.reshape(test_list,(TotalInstance,TotalfeatNos))

    score = final_model.evaluate(test_list, Y_test, verbose=0)
    preds = final_model.predict(test_list, verbose=0)

    ftest = open('DNNtest.txt','a')
    ftest.write(str(score[0]))
    ftest.write(' ')
    ftest.write(str(score[1]))
    ftest.write('\n')
    ftest.close()
    
    print(filename+':  '+str(score))
    return

################################################################################################################################################################
  #callback 

  date = datetime.date.fromtimestamp(time.time())
  strdate = str(date)
  basename = os.path.basename(filename)
  #logPath = os.path.dirname(filename)
  logPath = "./static/log/"
  logPath += basename[:-5]
  filepath=logPath+'model_Ws_'+strdate+'_'+str(learningRate)+'_Dr'+str(dropRate)+'_L1-'+str(L1)+'_L2-'+str(L2)+'_AllT|OneF-'+str(AllTorOneF)+'.h5'
  if NoValids == False:
    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
  else:
    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
  callbacks_list = [checkpoint]

################################################################################################################################################################
  #Fit the model

  print('start model fitting')
  startfit = time.time()
  TotalfeatNos = featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]
  TotalInstance = np.shape(X_train)[0]
  train_list = np.empty(TotalfeatNos*TotalInstance)
  print(TotalfeatNos)

  t=0
  for k in range(TotalInstance):
    prevIndex = 0
    for j in range(6):
      for i in range(featNos[j]):
        train_list[t] = X_train[k][prevIndex+i]
        t+=1
      prevIndex = prevIndex+featNos[j]

  train_list = np.reshape(train_list,(TotalInstance,TotalfeatNos))


  if NoCallBack == False:
    if NoValids == False:
      hist = final_model.fit(train_list, Y_train, validation_split=0.2, nb_epoch=noEpoch, callbacks=callbacks_list, verbose=2)
    else:
      hist = final_model.fit(train_list, Y_train, nb_epoch=noEpoch, callbacks=callbacks_list, verbose=2)
  else:
    if NoValids == False:
      hist = final_model.fit(train_list, Y_train, validation_split=0.2, nb_epoch=noEpoch, verbose=2)
    else:
      hist = final_model.fit(train_list, Y_train, nb_epoch=noEpoch, verbose=2)
  fittime = time.time()-startfit
  print('model fitted')

################################################################################################################################################################
  #evalaution

  TotalfeatNos = featNos[0]+featNos[1]+featNos[2]+featNos[3]+featNos[4]+featNos[5]
  TotalInstance = np.shape(X_test)[0]
  test_list = np.empty(TotalfeatNos*TotalInstance)

  t=0
  for k in range(TotalInstance):
    for j in range(6):
      prevIndex = 0
      for i in range(featNos[j]):
        test_list[t] = X_test[k][prevIndex+i]
        t+=1
      prevIndex = prevIndex+featNos[j]

  test_list = np.reshape(test_list,(TotalInstance,TotalfeatNos))

  score = final_model.evaluate(test_list, Y_test, verbose=0)
  preds = final_model.predict(test_list, verbose=0)

  print(score)
  print("fit time: "+str(fittime))

################################################################################################################################################################
  #log result

  logResult(filename, final_model, score, preds, Y_test, int(len(Y_train)*0.8), int(len(Y_train)*0.2), int(len(Y_test)*0.8), learningRate, dropRate, L1, L2, AllTorOneF, hist)

################################################################################################################################################################